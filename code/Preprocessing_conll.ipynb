{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Files\n",
    "Different sources and tools may make use of different formats to represent information and the output of various tools may not directly correspond. In this course, we will mainly (or even exclusively) work with the conll format. Even within this format, there may be differences in tokenization, class labels used or in the number of columns provided in the output. Depending on what the difference is exactly, you may want to adapt input files or build scripts that can deal with such differences during the process. In this case, we are preparing files that present output of two different tools for evaluation, where the exact annotation scheme differs. We set this up so you can first convert the files, so that they match and then can run evaluation (covered in a different notebook). Originally, both systems had a different tokenization and they both differed from the tokenization used in training and evaluation data. The steps of making sure that the tokens align have already been taken. We left some of the basic functions used as part of this process (e.g. the verification whether tokens align) as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_tokens(conll1: List, conll2: List) -> bool:\n",
    "    '''\n",
    "    Check whether the tokens of two conll files are aligned\n",
    "    \n",
    "    :param conll1: tokens (or full annotations) from the first conll file\n",
    "    :param conll2: tokens (or full annotations) from the first conll file\n",
    "    \n",
    "    :returns boolean indicating whether tokens match or not\n",
    "    '''\n",
    "    for i, row in enumerate(conll1):\n",
    "        row2 = conll2[i]\n",
    "        if row[0] != row2[0]:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_conll_file(conll_file: str, delimiter: str = '\\t'):\n",
    "    '''\n",
    "    Read in conll file and return structured object\n",
    "    \n",
    "    :param conll_file: path to conll_file\n",
    "    :param delimiter: specifies how columns are separated. Tabs are standard in conll\n",
    "    \n",
    "    :returns: List of splitted rows included in conll file\n",
    "    '''\n",
    "    conll_rows = []\n",
    "    with open(conll_file, 'r') as my_conll:\n",
    "        for line in my_conll:\n",
    "            row = line.strip(\"\\n\").split(delimiter)\n",
    "            if len(row) == 1:\n",
    "                conll_rows.append([\"\"]*rowlen)\n",
    "            else:\n",
    "                rowlen = len(row)\n",
    "                conll_rows.append(row)\n",
    "    return conll_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment_okay(conll1: str, conll2: str) -> bool:\n",
    "    '''\n",
    "    Read in two conll files and see if their tokens align\n",
    "    '''\n",
    "    my_first_conll = read_in_conll_file(conll1)\n",
    "    my_second_conll = read_in_conll_file(conll2)\n",
    "    \n",
    "    return matching_tokens(my_first_conll, my_second_conll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predefined_conversions(conversion_file: str) -> Dict:\n",
    "    '''\n",
    "    Read in file with predefined conversions and return structured object that maps old annotation to new annotation\n",
    "    \n",
    "    :param conversion_file: path to conversion file\n",
    "    \n",
    "    :returns object that maps old annotations to new ones\n",
    "    '''\n",
    "    conversion_dict = {}\n",
    "    my_conversions = open(conversion_file, 'r')\n",
    "    conversion_reader = csv.reader(my_conversions, delimiter='\\t')\n",
    "    for row in conversion_reader:\n",
    "        conversion_dict[row[0]] = row[1]\n",
    "    return conversion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_converted_output(conll_rows: List, annotation_identifier: int, conversions: Dict, outputfilename: str, IOB_col : int, delimiter: str = '\\t'):\n",
    "    '''\n",
    "    Check which annotations need to be converted for the output to match and convert them\n",
    "    Saves converted data in the outputfile\n",
    "    \n",
    "    :param conll_rows: rows with conll annotations\n",
    "    :param annotation_identifier: indicator of how to find the annotations in the object (index)\n",
    "    :param conversions: pointer to the conversions that apply. This can be external (e.g. a local file with conversions) or internal (e.g. prestructured dictionary). In case of an internal object, you probably want to add a function that creates this from a local file.\n",
    "    :param ourputfilename: path to outputfile\n",
    "    :param IOB_col : integer indicating the index of the column in which IOB labels are located\n",
    "    '''\n",
    "    with open(outputfilename, 'w') as outputfile:\n",
    "        for n, row in enumerate(conll_rows):\n",
    "            #add column headers to the very first line\n",
    "            if n == 0:\n",
    "                outputfile.write(delimiter.join([str(column_index) for column_index in range(len(row))])+\"\\n\")\n",
    "            annotation = row[annotation_identifier]\n",
    "            if annotation in conversions:\n",
    "                #get new annotation label\n",
    "                new_annotation = conversions.get(annotation)\n",
    "                #if token is part of a named entity, extract the prefic\n",
    "                if new_annotation != 'O':\n",
    "                    #if the prefix is defined, extract it, otherwise use 'B' indicating the beginning of a named entity\n",
    "                    IOB = row[IOB_col] if IOB_col != None else 'B'\n",
    "                    new_annotation = f\"{IOB}-{new_annotation}\"\n",
    "                #assign the new annotation\n",
    "                row[annotation_identifier] = new_annotation\n",
    "            if row[0] == \"\":\n",
    "                outputfile.write(\"\\n\")\n",
    "            else:\n",
    "                outputfile.write(delimiter.join(row)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_files(conll1: str, conll2: str, column_identifiers: List, conversions: Dict, IOB_col : int):\n",
    "    '''\n",
    "    Guides the full process of preprocessing files and outputs the modified files.\n",
    "    \n",
    "    :param conll1: path to the first conll input file\n",
    "    :param conll2: path to the second conll input file\n",
    "    :param column_identifiers: object providing the identifiers for target column\n",
    "    :param conversions: path to a file that defines conversions\n",
    "    :param IOB_col : integer indicating the index of the column in which IOB labels are located\n",
    "    '''\n",
    "    if alignment_okay(conll1, conll2):\n",
    "        conversions = get_predefined_conversions(conversions)\n",
    "        my_first_conll = read_in_conll_file(conll1)\n",
    "        my_second_conll = read_in_conll_file(conll2)\n",
    "        create_converted_output(my_first_conll, column_identifiers[0], conversions, conll1.replace('.conll','-preprocessed.conll'), IOB_col)\n",
    "        create_converted_output(my_second_conll, column_identifiers[1], conversions, conll2.replace('.conll','-preprocessed.conll'), IOB_col)\n",
    "    else:\n",
    "        print(conll1, conll2, 'do not align')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_files('../data/spacy_out.dev.conll','../data/conll2003.dev.conll', [2,3],'./settings/conversions.tsv', IOB_col=1)\n",
    "preprocess_files('../data/stanford_out.dev.conll','../data/conll2003.dev.conll', [3,3],'./settings/conversions.tsv', IOB_col= None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
